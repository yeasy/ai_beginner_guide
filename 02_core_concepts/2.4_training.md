## 2.4 怎么训练？就像反复做题并订正

> —— 训练、推理与损失函数

> 机器没有“灵感”，它通过反复试错和反馈逐步逼近正确答案。犯错就纠正，迭代就进步。

### 2.4.1 AI 是怎么读书的？

我们经常说“训练”（Training）这个词。
很多人脑补的画面是：机器人哪怕坐在图书馆里，如饥似渴地阅读人类的经典名著，然后突然顿悟了。

完全错了。
真实的训练过程，更像是一个 **只做练习题、靠反馈改错** 的学生。

这个学生（模型）什么都不懂，一上来就被迫做几百万道选择题。
1.  **瞎猜**：它看第一题（一张图片），瞎猜“是猫”。
2.  **反馈**：老师（算法）看了一眼标准答案“是狗”，告诉它这次偏差很大。
3.  **更新参数**：模型内部参数调了一下，记住“下次看到这种毛茸茸的东西，猜狗不猜猫”。

这个过程重复几亿次后，它就变成了一个“高熟练度刷题机器”，看到相似题型时更容易答对。
这就是 **“训练”**。

### 2.4.2 损失函数：痛苦的度量

在 AI 领域，偏差有多大，有一个专门的数学名字，叫 **“损失函数”（Loss Function）**。
你也可以把它叫作 **“误差指数”**。

*   猜对了：损失接近 0。
*   猜得离谱：损失很高。
*   猜得沾边：损失中等。

模型训练的核心优化目标之一，就是 **“让损失降到最低”**（Minimize Loss）。
它没有“理解世界”的主观意图，只是在参数空间里不断优化。
这听起来很冷酷，但也是最符合经济学原理的：**任何智能系统，本质上都是在追求成本最小化（Cost Minimization）。**

### 2.4.3 训练 vs 推理：十年寒窗与一朝成名

训练完了，模型出师了。这时候我们把它拿来用，给它一张新照片，它一眼认出“这是猫”。
这个使用的过程，叫 **“推理”（Inference）**。

这两个阶段的成本是天壤之别：
*   **训练（Training）**：是 **“造核弹”**。需要成千上万张显卡，耗电量相当于一个小城市，花好几个月，烧掉几亿美金。这是只有巨头才玩得起的游戏。
*   **推理（Inference）**：是 **“放鞭炮”**。训练好的模型，哪怕在你的手机上也能跑。每次问它一个问题，只消耗这一点点电。

所以，我们普通人、开发者，绝大多数时候是在做 **推理**，也就是在享受巨头们花巨资训练出来的成果。

### 2.4.4 思考题

既然 AI 主要是在“反复做题并优化误差”，那它真的 **“理解”** 它做的题吗？
一个只会做题、且正确率 100% 的机器，和一个真正理解题目意思的人类，有什么本质区别？
（提示：这就是著名的“中文房间”思想实验）
