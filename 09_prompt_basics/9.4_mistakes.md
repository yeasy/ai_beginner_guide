# 第九章：提示词工程入门

## 9.4 避免常见错误

在学习如何写好提示词的同时，也要知道哪些坑不能踩。

### 9.4.1 模棱两可

这是最常见的问题。我们习惯了人与人之间"你懂的"那种默契，但 AI 没有。

- ❌ **错误**："帮我写篇短一点的文章。"
  - （多短？100 字还是 1000 字？文章关于什么？）
- ✅ **正确**："写一篇关于'咖啡好处'的科普文章，字数控制在 300-500 字之间。"

### 9.4.2 信息过载

一次性给 AI 塞太多太杂的任务，它可能会"顾头不顾尾"，漏掉中间的要求。

- ❌ **错误**："帮我翻译这段话，顺便润色一下，然后提取关键词，再写个摘要，最后把这些都做成 PPT 大纲..."
- ✅ **正确**：**分步来**。
  - "第一步，请帮我翻译这段话。"
  - （等它回复后）"好，第二步，请帮我润色刚才的译文..."

### 9.4.3 否定指令（"不要..."）

AI 对于"否定"指令的理解有时候不如"肯定"指令好。就像你对孩子说"不要想大象"，他脑子里立刻就会出现大象。

- ❌ **不佳**："句子不要太长。"
- ✅ **更好**："请使用短句。"
- ❌ **不佳**："回答不要包含废话。"
- ✅ **更好**："请直接给出结论，保持简洁。"

**尽量告诉 AI "要做什么"，而不是"不要做什么"。**

### 9.4.4 盲信大模型的"记忆"

虽然现在的工具（如 ChatGPT、Perplexity）都能联网，但你需要区分**"它的记忆"**和**"它的搜索"**。

- ❌ **错误**：问一个纯文本模型（不联网）"2024 年奥运会冠军是谁？"。
  - 它的训练数据可能只到 2023 年，它可能会根据概率瞎编一个人名（幻觉）。
- ✅ **正确**：
  - 使用专门的**联网搜索模式**（Browsing）。
  - 对于极其精确的数据（如"1998年某天的具体股价"），最好还是查阅原始数据库或用 Perplexity 这样的引用式引擎。

### 9.4.5 自我设限

不要因为第一次回答不好就放弃。AI 是可以"调教"的。

- 场景：AI 写了一首诗，你觉得不好。
- ❌ **错误**：关掉窗口，心里骂一句"人工智障"。
- ✅ **正确**：追问。"写得太古板了，我希望更现代一点，像徐志摩那种风格，再试一次。"

**记住：好的结果通常不是一次生成的，而是通过几次对话"聊"出来的。**
