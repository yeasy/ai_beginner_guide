## 本章小结

本章深入介绍了机器学习的核心原理和三大主要范式，帮助读者理解 AI 系统"学习"的本质。

### 核心要点回顾

**机器学习的核心思想**
- 机器学习是从数据中自动学习规律的方法
- 核心目标是泛化——在新数据上表现良好
- 偏差-方差权衡是模型选择的基本考量
- 没有放之四海皆准的最优算法

**监督学习**
- 使用带标签的数据进行训练
- 分类：将样本划分到预定义类别
- 回归：预测连续数值
- 常见算法：决策树、随机森林、逻辑回归、神经网络
- 挑战：标注成本、类别不平衡、特征工程

**无监督学习**
- 处理无标签数据，发现内在结构
- 聚类：将相似样本分组（K-Means、层次聚类、DBSCAN）
- 降维：减少数据维度（PCA、t-SNE）
- 关联规则：发现数据项间的关联模式

**自监督学习**
- 介于监督与无监督之间，数据本身即标签
- 核心机制：掩码（Masking）与预测（Prediction）
- 解决了数据标注成本高昂的问题
- 是大语言模型（如 GPT、BERT）预训练的基础


**强化学习**
- 智能体通过与环境交互学习
- 核心要素：状态、动作、奖励、策略
- 探索与利用的权衡
- 经典案例：AlphaGo、游戏 AI、机器人控制

### 四大范式对比

| 范式 | 数据 | 学习方式 | 典型应用 |
|------|------|----------|----------|
| 监督学习 | 带标签 | 从示例学习 | 分类、回归 |
| 无监督学习 | 无标签 | 发现模式 | 聚类、降维 |
| 强化学习 | 交互产生 | 试错学习 | 游戏、控制 |
| 自监督学习 | 原始数据 | 自我预测 | 语言模型、预训练 |

### 关键术语

| 术语 | 解释 |
|------|------|
| 泛化 | 模型在新数据上的表现能力 |
| 过拟合 | 模型在训练集上好但在测试集上差 |
| 偏差 | 模型简化假设导致的系统性误差 |
| 方差 | 模型对训练数据变化的敏感度 |
| 聚类 | 将相似样本分到同一组 |
| 降维 | 减少数据维度同时保留重要信息 |
| 强化学习 | 通过与环境交互获得反馈来学习 |
| Q-Learning | 经典的强化学习算法 |
| 掩码 | 自监督学习中遮盖部分数据的方法 |
| 预训练 | 在大数据上进行自监督学习以获得通用能力 |

### 延伸思考

1. 为什么深度学习减少了对人工特征工程的依赖，但并未完全消除它？

2. 强化学习在游戏中取得了巨大成功，为什么在商业应用中仍相对有限？

3. 自监督学习是如何降低对标注数据依赖的？这对 AI 发展有什么影响？

### 下章预告

下一章将深入探讨深度学习，解析神经网络的工作原理，介绍关键的深度学习技术，以及主流的网络架构（如 CNN、RNN、[Transformer](../05_deep_learning/5.3_architectures.md)），让读者理解当今最先进 AI 系统的技术核心。
