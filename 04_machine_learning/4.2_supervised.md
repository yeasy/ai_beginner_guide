## 4.2 监督学习

> 监督学习就是“刷题”。有标签，叫监督；没标签，叫无监督。

### 4.2.1 填鸭式教育的胜利

**监督学习（Supervised Learning）** 是目前 AI 领域最成熟、应用最广的技术。

它的本质，就是一场 **填鸭式教育**。

想象一个 **“虎妈”**（算法）教育孩子（模型）：
1.  **刷题**：虎妈拿出一张照片（输入 X），问：“这是什么？”
2.  **回答**：孩子瞎猜：“是猫。”
3.  **打分**：虎妈看了一眼背面写着的标准答案（标签 Y），说：“错！这是狗。”
4.  **修正**：孩子挨了一手板，记住了这次教训。

在数据质量和训练流程都可靠的前提下，这种流程反复足够多次，模型识别能力通常会显著提升。

很多成熟 AI 应用（人脸识别、语音识别、垃圾邮件拦截）都建立在监督学习或其变体之上。

### 4.2.2 两种题型：选择题 vs 填空题

在监督学习的试卷上，主要有两种题型：

1.  **分类问题（Classification）** —— **做选择题**。
    *   答案是 **离散** 的，有限个选项。
    *   *例子*：这封邮件是垃圾邮件吗？（A. 是 / B. 否）
    *   *例子*：这个图是数字几？（A. 0 / B. 1 ... / J. 9）

2.  **回归问题（Regression）** —— **做填空题**。
    *   答案是 **连续** 的数字，可能性无限。
    *   *例子*：明天的房价是多少？（填：500万，501万...）
    *   *例子*：这孩子能长多高？（填：170cm，170.1cm...）

所以，区分它们的秘诀很简单：**看输出结果是不是“连贯”的数值。**

### 4.2.3 监督学习的代价：昂贵的“答案”

既然监督学习这么好用，为什么我们不把所有 AI 都做成监督学习？

因为 **“标准答案”（标签）** 太贵了。

这哪里是训练数据，简直是用黄金铺出来的。
**数据标注成本**，是阻碍监督学习发展最大的拦路虎。

> [!NOTE]
> 在工程实践中，监督学习决不止步于“模型预测-纠正”，它必须通过严密的数学与指标评估来防止模型“死记硬背”（即过拟合），确保其具备举一反三的能力（泛化能力）。一个标准的监督学习工程闭环包含：
> 1. **数据划分**：将数据集严格分为**训练集**（Training Set，通常占80%）和**测试集**（Test Set，通常占20%）。训练集用于学习规律，测试集用于考试验证。
> 2. **目标函数（Loss Function）**：衡量模型预测值与真实标签之间差距的公式（如回归问题的均方误差 MSE，分类问题的交叉熵）。
> 3. **优化算法**：通过特定的算法（最典型的如梯度下降法）不断微调千千万万个内部参数（权重与偏差），使得目标函数（误差）尽可能地缩小。
> 4. **可观测评估指标**：在测试集上计算成绩。分类问题看准确率（Accuracy）、精确率（Precision）和召回率（Recall）；回归问题看均方根误差（RMSE）等。
> 
> 请参阅本书配套仓库中的 [`labs/01_ml_basics.py`](../labs/01_ml_basics.py)。该实验使用基础的 `Scikit-learn` 库构建了一个极简的房价预测（线性回归）模型，展现了从制造模拟数据、划分测试集，到拟合模型并输出 RMSE 评估指标的连贯、可复现过程体验。

### 4.2.4 思考题

假设你想做一个“预测股票涨跌”的 AI。
1.  这是一个分类问题（涨/跌）还是回归问题（涨多少点）？
2.  它的“标签”（标准答案）从哪里来？需要人工标注吗，还是可以自动获得？（这一点决定了它是否昂贵）
