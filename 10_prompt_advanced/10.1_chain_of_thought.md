## 10.1 思维链（CoT）

> 结果很可能是凑出来的，过程才是逻辑的体现。Let's think step by step.

### 10.1.1 为什么 AI 会做错小学数学题？

如果你问 GPT-3 一个这样的问题：
> “小明有 5 个苹果，吃了 2 个，又买了 3 筐，每筐 10 个，现在有几个？”

它可能会直接回一个数字：35。

但如果是更复杂的逻辑题，它很可能会算错，比如算出 30 或者 40。

因为它像个 **心算很快但粗心大意的小学生**，它是凭“直觉”（概率）猜一个数字，而不是真的在算。

### 10.1.2 一句话，可能显著提升稳定性

怎么样让它变聪明？

只需要加一句咒语：
> **请一步一步地思考（Let's think step by step）。**

> **更稳妥的写法（推荐）**
> 如果你不需要它把“思考过程”写得很长，可以改成：**“请给出可检查的关键步骤/中间结果，并在最后给出答案。”**

一旦你加了这句话，也就是引导它使用 **思维链（CoT）**，它更可能给出类似下面这种“可检查步骤”的回答（不同模型/产品可能会隐藏或简化部分思考过程）：
> 好的。
> 1. 起始有 5 个苹果。
> 2. 吃了 2 个，剩下 5 - 2 = 3 个。
> 3. 买了 3 筐，每筐 10 个，共 3 * 10 = 30 个。
> 4. 总数 = 剩下的 3 个 + 新买的 30 个 = 33 个。
> **答案是 33。**

你看，虽然它可能本来想蒙 35，但一旦被逼着写出了 **计算过程（草稿纸）**，它自己就发现了逻辑链条，从而得出了正确答案。

### 10.1.3 隐式推理 vs 显式推理

近年的一些“更擅长推理”的模型与产品形态，已经把部分思维链能力内化了。你在界面上可能会看到它在“思考中...”。

这叫 **慢思考（System 2 Thinking）**。
*   **快思考（System 1）**：脱口而出，凭直觉，容易错。
*   **慢思考（System 2）**：深思熟虑，有逻辑，更准确。

当我们面对复杂任务（如写代码、做策划、算账）时，可以主动引导 AI 给出可检查的关键步骤，再由你复核结果。

### 10.1.4 思考题

在工作中，你向老板汇报时，是直接给结论（System 1），还是展示你的推导过程（System 2）？

哪种方式更有说服力？

其实，AI 和老板一样，都喜欢看 **路书**。
