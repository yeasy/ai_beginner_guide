## 6.3 预训练与微调

> **说明**
> **本讲核心**：通用大模型是"通才"，垂直行业模型是"专才"。
> **一句话口诀**：预训练练内功，微调练招式。

### 6.3.1 预训练（Pre-training）：通识教育

训练像 **新一代大模型（以 GPT 系列为例）** 这样的大模型，第一步叫做 **预训练**。
这就是 **"上大学"**。
OpenAI 把全网的数据喂给它，不分学科，什么都学。物理、化学、编程、莎士比亚、八卦新闻...
这个阶段 **极其昂贵**（通常需要超大规模 GPU 集群，训练周期也可能按月计算）。

**目标**：让 AI 掌握人类的语言规律和世界的基本知识。
**结果**：它变成了一个博学多才，但不太懂规矩的"野人"。你问它"怎么制造炸弹"，它可能真的会告诉你。

### 6.3.2 后来微调（SFT）：岗前培训

这就需要第二步：**微调（Supervised Fine-Tuning）**。
这就是 **"岗前培训"**。
我们雇佣人类老师，写好标准的"问答对"（Instruction），教它如何对话，如何有礼貌，通过什么该说什么不该说。

这个阶段 **便宜** 得多。
**目标**：把"野人"变成"客服"、"医生"或"程序员"。
**结果**：它学会了遵循指令，变成了一个好用的助手。

### 6.3.3 RLHF：去人类社会实习

最后一步是 **人类反馈强化学习（RLHF）**。
这就是 **"实习"**。
让 AI 直接面对用户，根据用户的反馈（点赞/点踩）来调整。
这一步让 AI 真正有了"情商"，知道什么样的回答最讨人喜欢。

### 6.3.4 思考题

很多公司想拥有自己的"行业大模型"（比如法律大模型）。
他们通常不需要从头做"预训练"（太贵了），而是在通用模型的基础上做"微调"。
这就好比：你是想自己从幼儿园开始培养一个律师（预训练），还是直接招一个法学毕业生，给他培训两周你们公司的规定（微调）？
显然是后者。**"微调"是 AI 落地的必经之路。**
